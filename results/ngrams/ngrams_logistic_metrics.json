{
  "accuracy": 0.864105123087159,
  "macro_precision": 0.8611950096546563,
  "macro_recall": 0.8668052898632953,
  "macro_f1": 0.8636075085611304,
  "per_class_metrics": {
    "Business": {
      "precision": 0.8414239482200647,
      "recall": 0.8378088077336198,
      "f1-score": 0.8396124865446717,
      "f1": 0.8396124865446717,
      "support": 1862
    },
    "Entertainment": {
      "precision": 0.8743260058067192,
      "recall": 0.9197207678883071,
      "f1-score": 0.8964490750584733,
      "f1": 0.8964490750584733,
      "support": 2292
    },
    "Health": {
      "precision": 0.8345802161263508,
      "recall": 0.8685121107266436,
      "f1-score": 0.8512081390419669,
      "f1": 0.8512081390419669,
      "support": 1156
    },
    "Politics": {
      "precision": 0.8755261575466026,
      "recall": 0.8802902055622733,
      "f1-score": 0.8779017184202593,
      "f1": 0.8779017184202593,
      "support": 1654
    },
    "Science": {
      "precision": 0.8215384615384616,
      "recall": 0.8361169102296451,
      "f1-score": 0.8287635799275738,
      "f1": 0.8287635799275738,
      "support": 958
    },
    "Sports": {
      "precision": 0.9389587073608617,
      "recall": 0.9567073170731707,
      "f1-score": 0.9477499244941106,
      "f1": 0.9477499244941106,
      "support": 1640
    },
    "Technology": {
      "precision": 0.8420115709835336,
      "recall": 0.768480909829407,
      "f1-score": 0.8035676364408579,
      "f1": 0.8035676364408579,
      "support": 2462
    }
  },
  "num_samples": 12024,
  "training_time_seconds": 42.56065392494202
}